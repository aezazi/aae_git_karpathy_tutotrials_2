Running in distributed environment. Initializing FSDP

Running in distributed environment. Initializing FSDP


GPTConfig instantiated with block size: 1024, vocab size: 50304, n_layer: 12, n_head: 12, n_embd: 768
GPTConfig instantiated with block size: 1024, vocab size: 50304, n_layer: 12, n_head: 12, n_embd: 768


FSDP initialized on device: cuda:0, rank: 0, local rank: 0, world size: 2


FSDP initialized on device: cuda:1, rank: 1, local rank: 1, world size: 2

Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1

Total parameters: 237,092,400


Total parameters: 237,092,400


Optimizer initialized on GPU rank 1, device cuda:1

Optimizer initialized on GPU rank 0, device cuda:0

Scheduler initialized on GPU rank 1, of 2


effective batch size desired: 524288
accumulation steps desired: 16

Scheduler initialized on GPU rank 0, of 2

[DEBUG] Rank 1  started training step: 0
[DEBUG] Rank 0  started training step: 0
[DEBUG] Rank 1: Getting gate assignments...
[DEBUG] Input shapes across ranks: [(16384, 768), (16384, 768)]
[DEBUG] Rank 0: Getting gate assignments...
[DEBUG] Rank 0: Gate assignments complete, top_k_ids shape: torch.Size([16384, 2])
[DEBUG] Rank 1: Gate assignments complete, top_k_ids shape: torch.Size([16384, 2])
[DEBUG] Rank 0: Getting expert assignments...
[DEBUG] Rank 1: Getting expert assignments...
[DEBUG] Rank 0: Sending 14539 tokens to GPU 0
[DEBUG] Rank 0: Sending 12612 tokens to GPU 1
[DEBUG] Rank 0: Starting token communication...
----------------------------------------------------------------------
[DEBUG] Rank 0 entered _communicate_tokens
[DEBUG] Rank 0 shape token_expert_local_id_assignments_padded : torch.Size([14539, 2])
[DEBUG] Rank 0 token_weights_padded: torch.Size([14539, 2])
[DEBUG] Rank 0 send_tokens shape: torch.Size([14539, 768])
[DEBUG] Rank 0 send_expert_ids shape: torch.Size([14539, 2])
[DEBUG] Rank 0 send_weights shape: torch.Size([14539, 2])
[DEBUG] Rank 0 send_mask shape: torch.Size([14539, 2])
[DEBUG] Rank 0 send counts in loop: [14539]
[DEBUG] Rank 0 shape token_expert_local_id_assignments_padded : torch.Size([12612, 2])
[DEBUG] Rank 0 token_weights_padded: torch.Size([12612, 2])
[DEBUG] Rank 0 send_tokens shape: torch.Size([12612, 768])
[DEBUG] Rank 0 send_expert_ids shape: torch.Size([12612, 2])
[DEBUG] Rank 0 send_weights shape: torch.Size([12612, 2])
[DEBUG] Rank 0 send_mask shape: torch.Size([12612, 2])
[DEBUG] Rank 0 send counts in loop: [14539, 12612]
[DEBUG] Rank 0 send counts after looping gpus: [14539, 12612]
[DEBUG] Rank 0 send_counts = [14539, 12612], sum = 27151, tensor_rows = 12612
[DEBUG] Rank 0 input_split_sizes_tensor: tensor([14539, 12612], device='cuda:0', dtype=torch.int32)
[DEBUG] Rank 0 initiating dist.all_to_all_single(recv_counts, send_counts)
[DEBUG] Rank 1: Sending 14727 tokens to GPU 0
[DEBUG] Rank 1: Sending 12586 tokens to GPU 1
[DEBUG] Rank 1: Starting token communication...
----------------------------------------------------------------------
[DEBUG] Rank 1 entered _communicate_tokens
[DEBUG] Rank 1 shape token_expert_local_id_assignments_padded : torch.Size([14727, 2])
[DEBUG] Rank 1 token_weights_padded: torch.Size([14727, 2])
[DEBUG] Rank 1 send_tokens shape: torch.Size([14727, 768])
[DEBUG] Rank 1 send_expert_ids shape: torch.Size([14727, 2])
[DEBUG] Rank 1 send_weights shape: torch.Size([14727, 2])
[DEBUG] Rank 1 send_mask shape: torch.Size([14727, 2])
[DEBUG] Rank 1 send counts in loop: [14727]
[DEBUG] Rank 1 shape token_expert_local_id_assignments_padded : torch.Size([12586, 2])
[DEBUG] Rank 1 token_weights_padded: torch.Size([12586, 2])
[DEBUG] Rank 1 send_tokens shape: torch.Size([12586, 768])
[DEBUG] Rank 1 send_expert_ids shape: torch.Size([12586, 2])
[DEBUG] Rank 1 send_weights shape: torch.Size([12586, 2])
[DEBUG] Rank 1 send_mask shape: torch.Size([12586, 2])
[DEBUG] Rank 1 send counts in loop: [14727, 12586]
[DEBUG] Rank 1 send counts after looping gpus: [14727, 12586]
[DEBUG] Rank 1 send_counts = [14727, 12586], sum = 27313, tensor_rows = 12586
[DEBUG] Rank 1 input_split_sizes_tensor: tensor([14727, 12586], device='cuda:1', dtype=torch.int32)
[DEBUG] Rank 1 initiating dist.all_to_all_single(recv_counts, send_counts)
[DEBUG] Rank 1 recv_counts: [12612, 12586]
[DEBUG] Rank 0 recv_counts: [14539, 14727]
[DEBUG] Rank 1 N_recv: 25198
[DEBUG] Rank 0 N_recv: 29266

after all to all

recv tokens flat type: <class 'torch.Tensor'>
after all to all


recv tokens flat type: <class 'torch.Tensor'>
recv tokens flat[0]type: <class 'torch.Tensor'>
recv tokens flat[0]type: <class 'torch.Tensor'>
tensor([[-0.6603,  1.4664, -2.0283,  ..., -2.5188, -1.5531,  1.1216],
        [-0.0206,  1.0530, -0.0684,  ..., -0.6291, -3.5399,  0.2567],
        [-0.1193,  2.5328,  0.1750,  ...,  0.1167, -2.9627, -0.9365],
        ...,
        [-2.7438, -0.4154, -0.6484,  ..., -1.7603, -0.5287, -0.9050],
        [-1.2202,  0.4806, -1.1232,  ..., -1.7225,  0.0444, -0.3257],
        [-1.8926,  1.9401, -1.3023,  ..., -0.6211, -0.8981,  1.0728]],
       device='cuda:0')
tensor([[-0.6603,  1.4664, -2.0283,  ..., -2.5188, -1.5531,  1.1216],
        [ 0.7716,  3.0206, -0.6433,  ..., -1.1497, -1.7753,  0.5258],
        [ 0.7732,  1.7949,  0.3880,  ..., -0.1529, -2.6636,  0.0137],
        ...,
        [-0.6697,  1.7638, -0.8852,  ..., -0.8460, -3.0561, -0.7363],
        [-0.8981,  0.9513,  0.1860,  ..., -0.9275, -1.2755, -1.2504],
        [-1.8675,  0.8933,  0.9755,  ..., -1.5717, -0.3146, -0.7213]],
       device='cuda:1')
<class 'torch.Tensor'>
<class 'torch.Tensor'>
tensor([ True, False], device='cuda:0')
tensor([ True, False], device='cuda:1')
recv_tokens shape: torch.Size([29266, 768]) sample:
tensor([[-0.6603,  1.4664, -2.0283,  ..., -2.5188, -1.5531,  1.1216],
        [-0.0206,  1.0530, -0.0684,  ..., -0.6291, -3.5399,  0.2567],
        [-0.1193,  2.5328,  0.1750,  ...,  0.1167, -2.9627, -0.9365],
        ...,
        [-2.7438, -0.4154, -0.6484,  ..., -1.7603, -0.5287, -0.9050],
        [-1.2202,  0.4806, -1.1232,  ..., -1.7225,  0.0444, -0.3257],
        [-1.8926,  1.9401, -1.3023,  ..., -0.6211, -0.8981,  1.0728]],
       device='cuda:0')

recv_tokens shape: torch.Size([25198, 768]) sample:
tensor([[-0.6603,  1.4664, -2.0283,  ..., -2.5188, -1.5531,  1.1216],
        [ 0.7716,  3.0206, -0.6433,  ..., -1.1497, -1.7753,  0.5258],
        [ 0.7732,  1.7949,  0.3880,  ..., -0.1529, -2.6636,  0.0137],
        ...,
        [-0.6697,  1.7638, -0.8852,  ..., -0.8460, -3.0561, -0.7363],
        [-0.8981,  0.9513,  0.1860,  ..., -0.9275, -1.2755, -1.2504],
        [-1.8675,  0.8933,  0.9755,  ..., -1.5717, -0.3146, -0.7213]],
       device='cuda:1')

recv_mask_flat shape: torch.Size([29266, 2]) sample:
tensor([[ True, False],
        [ True, False],
        [ True, False],
        [ True, False],
        [ True, False],
        [ True, False],
        [ True, False],
        [ True, False],
        [ True, False],
        [ True, False]], device='cuda:0')

recv_mask_flat shape: torch.Size([25198, 2]) sample:
tensor([[ True, False],
        [ True,  True],
        [ True,  True],
        [ True, False],
        [ True,  True],
        [ True, False],
        [ True,  True],
        [ True, False],
        [ True, False],
        [ True, False]], device='cuda:1')

[DEBUG] Rank 0: Token communication complete, received 29266 tokens
[DEBUG] Rank 1: Token communication complete, received 25198 tokens

[DEBUG] recv_tokens: tensor([[-0.6603,  1.4664, -2.0283,  1.0832,  1.4664, -0.3959, -0.0663],
        [-0.0206,  1.0530, -0.0684,  2.0670,  2.2221,  0.4416, -1.5834],
        [-0.1193,  2.5328,  0.1750,  0.7508,  0.5540,  0.3991,  0.1403],
        [-0.6697,  1.7638, -0.8852,  0.7606,  1.3092, -1.5984, -0.6736],
        [-0.8981,  0.9513,  0.1860,  0.4250,  1.7104,  0.2132, -1.5943],
        [-1.8675,  0.8933,  0.9755,  1.6657, -0.3290, -1.0952, -0.1841],
        [-0.0215, -0.1290, -1.4955,  1.3034, -1.1533, -0.5260, -0.2869],
        [-2.7438, -0.4154, -0.6484,  1.5068,  0.3479, -1.0761, -0.4026],
        [-1.2202,  0.4806, -1.1232, -0.9073,  1.2913, -1.5198, -0.0812],
        [-1.8926,  1.9401, -1.3023, -0.1579,  1.6223, -0.5984, -0.3849]],
       device='cuda:0')
[DEBUG] Rank 0: Processing 29266 tokens through local experts

[DEBUG] recv_tokens: tensor([[-0.6603,  1.4664, -2.0283,  1.0832,  1.4664, -0.3959, -0.0663],
        [ 0.7716,  3.0206, -0.6433,  1.2234,  1.7298,  1.5908, -0.9859],
        [ 0.7732,  1.7949,  0.3880,  2.4834,  0.7568,  0.6284, -0.6529],
        [-0.0206,  1.0530, -0.0684,  2.0670,  2.2221,  0.4416, -1.5834],
        [-0.8333,  1.4109,  1.3974,  2.0434,  0.4654, -0.1839,  0.0676],
        [-0.1193,  2.5328,  0.1750,  0.7508,  0.5540,  0.3991,  0.1403],
        [-0.7236,  1.0258,  0.3279,  2.1820,  0.2081,  1.3377, -0.5297],
        [-0.6697,  1.7638, -0.8852,  0.7606,  1.3092, -1.5984, -0.6736],
        [-0.8981,  0.9513,  0.1860,  0.4250,  1.7104,  0.2132, -1.5943],
        [-1.8675,  0.8933,  0.9755,  1.6657, -0.3290, -1.0952, -0.1841]],
       device='cuda:1')
[DEBUG] Rank 0: Input shapes - tokens: torch.Size([29266, 768]), expert_ids: torch.Size([29266, 2]), weights: torch.Size([29266, 2]), mask: torch.Size([29266, 2])
[DEBUG] Rank 1: Processing 25198 tokens through local experts

[DEBUG] mask: tensor([[ True, False],
        [ True, False],
        [ True, False],
        ...,
        [ True, False],
        [ True, False],
        [ True, False]], device='cuda:0')

[DEBUG] Rank 1: Input shapes - tokens: torch.Size([25198, 768]), expert_ids: torch.Size([25198, 2]), weights: torch.Size([25198, 2]), mask: torch.Size([25198, 2])
[DEBUG] Rank 0: Starting token-by-token processing...
[DEBUG] Rank 0: Processing token 0/29266
[DEBUG] mask: tensor([[ True, False],
        [ True,  True],
        [ True,  True],
        ...,
        [ True, False],
        [ True, False],
        [ True, False]], device='cuda:1')


[DEBUG] Rank 1: Starting token-by-token processing...
[DEBUG] token shape: torch.Size([768])
[DEBUG] Rank 1: Processing token 0/25198
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4654, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5346, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4815, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5144, 0.4856], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5718, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6353, 0.3647], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5185, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4036, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6545, 0.3455], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3203, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4282, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7259, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5129, 0.4871], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4349, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5964, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6058, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6797, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4523, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5923, 0.4077], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2741, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6302, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5651, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6619, 0.3381], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6641, 0.3359], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3652, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3942, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4307, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5670, 0.4330], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6496, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.5283, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3698, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4776, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5265, 0.4735], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7360, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4446, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2848, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6348, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6334, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5693, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6107, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3504, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4904, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4523, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4732, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4717, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4600, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5386, 0.4614], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5224, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5395, 0.4605], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2640, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3285, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7152, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6914, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3666, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6087, 0.3913], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3893, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5297, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5096, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6549, 0.3451], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5738, 0.4262], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5699, 0.4301], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5268, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5576, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5825, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4600, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5908, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5820, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6715, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5259, 0.4741], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3086, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5015, 0.4985], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5164, 0.4836], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5660, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4703, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5317, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4424, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6663, 0.3337], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4175, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.4844], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4092, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4180, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7227, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4340, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7417, 0.2583], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4683, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5259, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2773, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6976, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.4980], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4787, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5962, 0.4038], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5860, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5205, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4741, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3024, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4325, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5436, 0.4564], device='cuda:1')here

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.4426], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5213, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.4844], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4140, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6241, 0.3759], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6836, 0.3164], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4795, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.4712, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6442, 0.3558], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6914, 0.3086], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5675, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3691, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.6311, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5288, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6628, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4537, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5246, 0.4754], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7082, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6309, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6223, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3689, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4479, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3372, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.2422, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5463, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5889, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2918, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2744, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3777, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5917, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6386, 0.3614], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5557, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5521, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4417, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7578, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5171, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4111, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5969, 0.4031], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7256, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4819, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4083, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7158, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4443, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5583, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7237, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4829, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3675, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5181, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5665, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2842, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4712, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2763, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6325, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4335, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5511, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5288, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5254, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4489, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5675, 0.4325], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4040, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6123, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.3217, 0.0000], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4489, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5034, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4746, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.4980], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')here

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5511, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3554, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5960, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4530, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3877, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2918, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5297, 0.4703], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4795, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6783, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2600, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4966, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.4941], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4562, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2474, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6446, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7180, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5470, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7082, 0.0000], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.5334, 0.4666], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5205, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3709, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token shape: torch.Size([768])

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7400, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4321, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5511, 0.4489], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4608, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4465, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6433, 0.3567], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6794, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5438, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5424, 0.4576], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7005, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7526, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6760, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2820, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4500, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5280, 0.4720], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.4951], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6291, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4311, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6079, 0.3921], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6077, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5297, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5392, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4206, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5535, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5802, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3206, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5580, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5068, 0.4932], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token shape: torch.Size([768])

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5571, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2995, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.4912], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5885, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5440, 0.4560], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3621, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7379, 0.2621], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6298, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3240, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6843, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6359, 0.3641], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.4321], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5500, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6167, 0.3833], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6990, 0.3010], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2846, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.4893], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4552, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5689, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6067, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3923, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4703, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5902, 0.4098], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5794, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6046, 0.3954], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6186, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4198, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5220, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4420, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5322, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5974, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4429, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.8045, 0.1955], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4115, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4026, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6379, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5482, 0.4518], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3702, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4620, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.3157, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5896, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6549, 0.3451], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6388, 0.3612], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6624, 0.3376], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7154, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6487, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5448, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4537, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5469, 0.4531], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4216, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3933, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6370, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5631, 0.4369], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5703, 0.4297], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4054, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5562, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.3814, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5054, 0.4946], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7045, 0.2955], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5908, 0.4092], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4941, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4780, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4567, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5508, 0.4492], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3914, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4678, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4026, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4045, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5228, 0.4772], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7578, 0.2422], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5974, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.5380, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7046, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4104, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5944, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5248, 0.4752], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5361, 0.4639], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3513, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6259, 0.3741], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6451, 0.3549], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4069, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5170, 0.4830], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5612, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.4688], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4140, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5463, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6779, 0.3221], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5784, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5185, 0.4815], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7439, 0.2561], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2944, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3630, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6841, 0.3159], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5204, 0.4796], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6451, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5946, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4715, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4438, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2376, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5433, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6504, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6086, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5329, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5955, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4600, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.4902], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3247, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5297, 0.4703], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2954, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4056, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.4902], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5578, 0.4422], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5423, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4003, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5251, 0.4749], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6105, 0.3895], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5931, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4388, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5044, 0.4956], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7158, 0.2842], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7541, 0.2459], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5860, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5056, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4780, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7056, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3094, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5268, 0.4732], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.6619, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6028, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3549, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
here

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5285, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3858, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4897, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5736, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7624, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7264, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3496, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3589, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.4533], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4671, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4932, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.6811, 0.3189], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6156, 0.3844], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4192, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6753, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7301, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5438, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5875, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6935, 0.3065], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3732, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5929, 0.4071], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6197, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4577, 0.0000], device='cuda:1')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3156, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5997, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5047, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5221, 0.4779], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.4649], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6792, 0.3208], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7082, 0.2918], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4504, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3933, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4944, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6976, 0.3024], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5220, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4273, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2444, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6906, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.4951], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5535, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3381, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3891, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5265, 0.4735], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6032, 0.3968], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3972, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2699, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6142, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3979, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5103, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5239, 0.4761], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7666, 0.2334], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6280, 0.3720], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5100, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4264, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4854, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2736, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6366, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6411, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.4494], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5068, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5825, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5808, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7278, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2699, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5332, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4562, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4125, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6268, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6222, 0.3778], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3803, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6844, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4941, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4953, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4790, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5823, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5496, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3491, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6067, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.4863], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7044, 0.2956], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5390, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5727, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7556, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5927, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7341, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4465, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2881, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5301, 0.4699], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4905, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4316, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6460, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5283, 0.4717], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5501, 0.4499], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6109, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.4649], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7219, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7301, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5870, 0.4130], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3442, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7291, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6021, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5703, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4900, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4854, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4596, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3634, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6631, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5430, 0.4570], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5722, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4175, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5892, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2722, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4854, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5401, 0.4599], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6142, 0.0000], device='cuda:0')here

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6680, 0.3320], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2938, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4668, 0.0000], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.4600], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6011, 0.3989], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5898, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5359, 0.4641], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4771, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7801, 0.2199], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5210, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5261, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4177, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5753, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6509, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4306, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4610, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5381, 0.0000], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4897, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4073, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7493, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.4844], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3004, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7175, 0.2825], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2659, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4477, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7119, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6663, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5095, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7502, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5684, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5948, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3540, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5528, 0.4472], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5584, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4121, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2886, 0.0000], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.2781, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5513, 0.4487], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5205, 0.4795], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4069, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6558, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6828, 0.3172], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2709, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7005, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5476, 0.4524], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.4292], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.4297, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4571, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4187, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5256, 0.4744], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5550, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5404, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
herehere

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2418, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5417, 0.4583], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4572, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3369, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4907, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4278, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4533, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4108, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7373, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6665, 0.3335], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7029, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3858, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4746, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7062, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4412, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5185, 0.4815], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5660, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6130, 0.3870], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3699, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4102, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4397, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5229, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5361, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4739, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.4922], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4247, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5694, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.4951], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4619, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4330, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5103, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2507, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6996, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3203, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5523, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4678, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3337, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6922, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5299, 0.4701], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6827, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2498, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4052, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.4378], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5669, 0.4331], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6209, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4292, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6706, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5255, 0.4745], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.4785], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5112, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5054, 0.4946], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.4990], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4416, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6150, 0.3850], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4571, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5813, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7114, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5240, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5931, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3585, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2995, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4941, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4206, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5443, 0.4557], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.6044, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6678, 0.3322], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5830, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5813, 0.0000], device='cuda:1')[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4450, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5293, 0.4707], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4980, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6758, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4121, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7582, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4097, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5428, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4562, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5093, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.4980], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5264, 0.4736], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3311, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5448, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2627, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5404, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2971, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6877, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4523, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5832, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5254, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5272, 0.4728], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6111, 0.3889], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5588, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4007, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4340, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4897, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6301, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6243, 0.3757], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.4727], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4639, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.4417, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5670, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4980, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4435, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5370, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6797, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5380, 0.4620], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5322, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3078, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4235, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3173, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4659, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5063, 0.4937], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7050, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3791, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.6149, 0.3851], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.3294, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4455, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.4484], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4888, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.4446], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4187, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4306, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4760, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5890, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.6415, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6205, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5856, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5794, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6490, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3956, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5917, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4170, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6505, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3242, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5438, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7380, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5903, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5438, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6305, 0.3695], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6418, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5352, 0.4648], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7498, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6689, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6514, 0.3486], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4552, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6206, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4596, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5830, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3123, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4937, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4168, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7233, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5877, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6142, 0.3858], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6326, 0.3674], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5993, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5784, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6176, 0.3824], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4863, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5103, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2415, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6206, 0.3794], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5641, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6108, 0.3892], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5583, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4216, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5565, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5414, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4630, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4659, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4169, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6169, 0.3831], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2898, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5765, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6615, 0.3385], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4147, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2950, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3720, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4737, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5545, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7005, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5663, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5028, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5694, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4455, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4110, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4301, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3795, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6851, 0.3149], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4144, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3510, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5370, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5012, 0.4988], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4225, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4083, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7312, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7150, 0.2850], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3495, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4858, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5188, 0.4812], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4562, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.4863], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2620, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3099, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.8022, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5955, 0.4045], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6567, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4849, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5901, 0.4099], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3582, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5322, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2502, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4878, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6388, 0.3612], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5813, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7334, 0.2666], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5593, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2928, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3794, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7015, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4170, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4956, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7404, 0.2596], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4378, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5063, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4000, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2767, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3007, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4123, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2602, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4216, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.4867, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7235, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7585, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4292, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4359, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5784, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6164, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6262, 0.3738], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4586, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4321, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6536, 0.3464], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6851, 0.3149], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.4533], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5831, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7102, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6924, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5853, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4688, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6280, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4905, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.8072, 0.1928], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.2995, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6549, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4337, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6918, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4972, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5545, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5496, 0.4504], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.4902], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4751, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5699, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5827, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4321, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6895, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4630, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5249, 0.4751], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5775, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4012, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.2688, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5045, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5142, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3652, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6901, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4290, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.1978, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4311, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3433, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5161, 0.4839], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5151, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6289, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4475, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4678, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5122, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4369, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4187, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7044, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5161, 0.4839], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5808, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4407, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5699, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7072, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2985, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5438, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5044, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4751, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5288, 0.4712], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6000, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3998, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6993, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4634, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7398, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5254, 0.4746], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3363, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5133, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7578, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2765, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4802, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4282, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7556, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3836, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5773, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4737, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3076, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.4756], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2868, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5095, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3065, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3451, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6656, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3082, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6245, 0.3755], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4121, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.6491, 0.3509], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4664, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6447, 0.3553], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6442, 0.3558], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5249, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4196, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4173, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3105, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4980, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5988, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3675, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4955, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6348, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5054, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.4475], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5710, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6341, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5689, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6658, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3711, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4299, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5804, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5631, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4810, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2956, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5224, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4192, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4806, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4301, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4829, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.4436], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4562, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5576, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5249, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.6243, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6002, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4465, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5366, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6910, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6637, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4810, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2422, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3069, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5198, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4168, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5718, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2444, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4839, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4227, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4810, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5159, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4818, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6951, 0.3049], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4815, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7132, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6058, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6935, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.6761, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3344, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5725, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4688, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3817, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')here

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5336, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.4649], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.4397], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4475, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5775, 0.4225], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.4810], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5804, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.4727], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6589, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.0000], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3028, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6325, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3149, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4946, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3659, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3342, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2487, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6016, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5701, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.6824, 0.0000], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4196, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6481, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4830, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4776, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5194, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4795, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5171, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5872, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5058, 0.4942], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5976, 0.4024], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7264, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
here

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4424, 0.0000], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.4762, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3757, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7454, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5535, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5617, 0.4383], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3090, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6457, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6931, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6833, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5832, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5297, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5161, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4654, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6538, 0.3462], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5370, 0.0000], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.4873], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4841, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6206, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5182, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5545, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5185, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3976, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3942, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4795, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token shape: torch.Size([768])

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5023, 0.4977], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5856, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4829, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3239, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5771, 0.4229], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4275, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6183, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5521, 0.4479], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4780, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7221, 0.2779], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5665, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3411, 0.0000], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.5718, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6972, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6204, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6851, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5877, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4659, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5948, 0.4052], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token shape: torch.Size([768])

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6861, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7513, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5562, 0.4438], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3984, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6939, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5612, 0.4388], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2876, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5832, 0.4168], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5106, 0.4894], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5249, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3176, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3519, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2436, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5170, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5424, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5205, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3640, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4128, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3602, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2736, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4475, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5238, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5846, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6597, 0.3403], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5052, 0.4948], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5332, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5336, 0.4664], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2546, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4518, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6960, 0.3040], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2261, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3543, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5915, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3167, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4130, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4537, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4703, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7452, 0.0000], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5346, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5691, 0.4309], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4630, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5889, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4446, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3794, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6002, 0.3998], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4455, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4593, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6024, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4523, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5205, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5390, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4144, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3513, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5171, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3195, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5261, 0.4739], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6215, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.4961], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4819, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6128, 0.3872], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4620, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5220, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4668, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4335, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4282, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5099, 0.4901], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2991, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4397, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4576, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3796, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4863, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4123, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4092, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6619, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6280, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4854, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3394, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.3139, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3531, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5651, 0.4349], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5540, 0.4460], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3061, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4158, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7124, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5063, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5064, 0.4936], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.4388, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5993, 0.4007], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4751, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5143, 0.4857], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7564, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5288, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5040, 0.4960], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4849, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6007, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4576, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.6360, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5874, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6398, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5995, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3506, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.0000], device='cuda:1')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4685, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4154, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6414, 0.3586], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.4854], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4668, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5804, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7527, 0.2473], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5482, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5995, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7739, 0.0000], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4085, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6549, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5870, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5913, 0.4087], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5463, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7585, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5066, 0.4934], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5181, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5224, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2548, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6536, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5598, 0.4402], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4111, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.4321], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6114, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5025, 0.4975], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7300, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5407, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3746, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4610, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5318, 0.4682], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6487, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6805, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6132, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3785, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3733, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5181, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5769, 0.4231], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4187, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5380, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5332, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7678, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5129, 0.4871], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7009, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7547, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5424, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7686, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5210, 0.4790], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5908, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3381, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5443, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.3720, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4045, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6606, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5983, 0.4017], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6469, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6188, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5842, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2390, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4937, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6809, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5988, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5612, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6078, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5042, 0.4958], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6014, 0.3986], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4712, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6485, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5151, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4998, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3993, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7678, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.4810], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5052, 0.4948], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2705, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4126, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7763, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4005, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6494, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4995, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5315, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4196, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7025, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4005, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3425, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4121, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6023, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3451, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6984, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5052, 0.4948], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6487, 0.0000], device='cuda:0')here

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2415, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6025, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4819, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6151, 0.3849], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4776, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7592, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3464, 0.0000], device='cuda:1')
here[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6146, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5448, 0.4552], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3886, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4868, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2700, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3670, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6254, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.4494], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3868, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6267, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5511, 0.4489], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4268, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5121, 0.4879], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5813, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6464, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2322, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4113, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2453, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3303, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2314, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.8480, 0.1520], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4557, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6610, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5955, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3812, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3652, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7610, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4927, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3191, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6334, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4012, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6480, 0.3520], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5909, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6056, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3922, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6339, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3515, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5753, 0.4247], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6477, 0.3523], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6465, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5002, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4140, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2322, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7295, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4746, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2237, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3844, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6539, 0.3461], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7535, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6238, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5005, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5332, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2975, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4907, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6575, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.4756], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3977, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.4378], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3016, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7054, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5335, 0.4665], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.5000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3513, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5138, 0.4862], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3975, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2408, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6500, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3854, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6657, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5132, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4062, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6575, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6330, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.6206, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6496, 0.3504], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')
here

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5732, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2926, 0.0000], device='cuda:0')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4795, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3536, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5850, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5887, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6593, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6697, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6151, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7379, 0.2621], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6035, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4688, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6749, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3390, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6105, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4523, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5293, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6943, 0.3057], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6348, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5073, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3666, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5651, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.1508, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4091, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3707, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3944, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6267, 0.3733], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3661, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4244, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3535, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.4854], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5860, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5271, 0.4729], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.4533, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6088, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5254, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.4854], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5025, 0.4975], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5660, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6156, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5602, 0.4398], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5699, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2465, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5375, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3762, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5249, 0.4751], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4668, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6030, 0.3970], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5901, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5093, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7902, 0.2098], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2946, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3860, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.4756], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3877, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3500, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3342, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3343, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4290, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5938, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
herehere

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5576, 0.4424], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5178, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.4263], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3425, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4688, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6424, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3794, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5513, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4571, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7001, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7074, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3520, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5205, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
herehere

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4644, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4150, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5784, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3407, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6697, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3849, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6229, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3965, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5907, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3251, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3895, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2767, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4707, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3115, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5461, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6206, 0.3794], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5203, 0.4797], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6038, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5287, 0.4713], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6225, 0.3775], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4349, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.8492, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6293, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2516, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5756, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4039, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3912, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6577, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4340, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2458, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7147, 0.2853], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4937, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5254, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7313, 0.2687], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6071, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4301, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5496, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4625, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2838, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5976, 0.4024], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7264, 0.2736], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5459, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4099, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6140, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4888, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4426, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5742, 0.4258], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6826, 0.3174], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6192, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6123, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6658, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6606, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5710, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6072, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4822, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4220, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.4961], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.4766], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3576, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4446, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4487, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4673, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2999, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4069, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6480, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6880, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4446, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6283, 0.3717], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5356, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4216, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5220, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3303, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4790, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3771, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4533, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4093, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5046, 0.4954], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3884, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3899, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7233, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4810, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6885, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3816, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4539, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2759, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3962, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3535, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5073, 0.4927], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3630, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5993, 0.4007], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5034, 0.4966], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3259, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7484, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5727, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5961, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5568, 0.4432], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3423, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6105, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6058, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7542, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4990, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5063, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3329, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5236, 0.4764], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4006, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4746, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4116, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3929, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3711, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4504, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3921, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7162, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5689, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3030, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7303, 0.2697], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4172, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4541, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.4980], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4571, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6401, 0.3599], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3989, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5293, 0.4707], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3082, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5112, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3808, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2241, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4352, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5267, 0.4733], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4815, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3394, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4458, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4567, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3928, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5780, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2201, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5938, 0.4062], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5327, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5931, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6527, 0.3473], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.3120, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3420, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4780, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6540, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5210, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6864, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5083, 0.4917], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7151, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
here

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5588, 0.4412], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5851, 0.4149], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4069, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3621, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6116, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3634, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6101, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2723, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3053, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6184, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4988, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7241, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6465, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4249, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6370, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.4321], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.4873], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6741, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.4263], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4273, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5815, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3895, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3942, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5010, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5689, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6671, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6215, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5994, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2999, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5884, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5395, 0.4605], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6289, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4121, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6079, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5903, 0.4097], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4311, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3919, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6970, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5828, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5530, 0.4470], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6011, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6918, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6474, 0.3526], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4688, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7759, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6142, 0.3858], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5648, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token shape: torch.Size([768])

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6114, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5185, 0.0000], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5542, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.6535, 0.0000], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5433, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5171, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7799, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3730, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6580, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4455, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5756, 0.4244], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3460, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.4321], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3136, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6649, 0.3351], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2849, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.4426], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5931, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3407, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6379, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3923, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6366, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5322, 0.4678], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7277, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6947, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5967, 0.4033], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5012, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5646, 0.4354], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5332, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5751, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5931, 0.0000], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4185, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4143, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3094, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5813, 0.4187], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5535, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4311, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3785, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4868, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7001, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4359, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3886, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5823, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6081, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6298, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5974, 0.4026], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.3886, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5495, 0.4505], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.4523], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5482, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3465, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5569, 0.4431], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4829, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7065, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5293, 0.4707], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6270, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5832, 0.4168], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5545, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6514, 0.3486], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6593, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5200, 0.4800], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6077, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6671, 0.3329], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4668, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4069, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3868, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6056, 0.3944], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5857, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6906, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4465, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5593, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5132, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5988, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5641, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6792, 0.3208], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6114, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6053, 0.3947], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4177, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3702, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2098, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.6798, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5479, 0.0000], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4518, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4504, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2935, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5355, 0.4645], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6132, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3905, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3907, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5911, 0.4089], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4581, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5882, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4407, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5996, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6809, 0.3191], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5765, 0.4235], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4012, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5593, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7902, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3346, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6676, 0.3324], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5283, 0.4717], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3202, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5214, 0.4786], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4521, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5112, 0.4888], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5496, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6118, 0.3882], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6095, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5931, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6093, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4388, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.4971], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5593, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6314, 0.3686], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5804, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4118, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3746, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4004, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6039, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4407, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5823, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6275, 0.3725], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4707, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4785, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] Rank 0: Processing token 1000/29266
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3296, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6654, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5068, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5636, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4069, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] Rank 1: Processing token 1000/25198
[DEBUG] token_weights: torch.Size([2]) tensor([0.6770, 0.0000], device='cuda:0')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5612, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3871, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4407, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4196, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3812, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6098, 0.3902], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.4494], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6254, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7454, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3961, 0.0000], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5946, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4177, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5293, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7361, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6704, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4708, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4932, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4600, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4364, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5550, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3230, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.4834], device='cuda:0')[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6129, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5414, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5827, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6188, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4863, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2546, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6269, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4054, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5648, 0.4352], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2639, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6885, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5292, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4700, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6593, 0.3407], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5722, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4450, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3242, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4586, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4173, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3835, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6383, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3731, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3212, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3115, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5794, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5300, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6373, 0.3627], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5670, 0.4330], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4862, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4278, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6758, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5777, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6243, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token shape: torch.Size([768])

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6165, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4378, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3617, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5531, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6788, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4206, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4737, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5138, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3217, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3294, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4223, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2854, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3757, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4154, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6496, 0.3504], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5322, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5641, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5901, 0.4099], device='cuda:1')
here[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6424, 0.3576], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4469, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.6330, 0.3670], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3835, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7326, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5787, 0.4213], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6783, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6706, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7146, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5530, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6100, 0.3900], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5846, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5917, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4678, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5139, 0.4861], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4359, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4980, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6478, 0.3522], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4239, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6165, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2674, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4216, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2here

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6993, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4913, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3840, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.4378], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')
here

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5670, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4470, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5516, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4659, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6215, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4083, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5593, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5761, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5559, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5936, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5784, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5149, 0.4851], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3007, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6220, 0.3780], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4149, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5087, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7105, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6628, 0.3372], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5722, 0.4278], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6160, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5259, 0.4741], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4330, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4477, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4484, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3785, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4407, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5373, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4441, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5190, 0.4810], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4064, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4446, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5936, 0.4064], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5851, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7046, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2895, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.4737], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4397, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6868, 0.3132], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4170, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6943, 0.3057], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4737, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6086, 0.3914], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6809, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6667, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5523, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token shape: torch.Size([768])

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6188, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4664, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token shape: torch.Size([768])

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7066, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4627, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
herehere

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5898, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7106, 0.2894], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2954, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5830, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.8482, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3191, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5742, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3333, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.4436], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4659, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.4824], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3812, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5732, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5336, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2934, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4102, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.4397], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.1518, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7142, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4258, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.4542], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4268, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5083, 0.4917], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6168, 0.3832], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6529, 0.3471], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4378, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6972, 0.3028], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2858, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6572, 0.3428], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4863, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4282, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4076, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5718, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4130, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5924, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5846, 0.4154], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4475, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5870, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4712, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5288, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4263, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4464, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5536, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6581, 0.3419], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4031, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5770, 0.4230], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4703, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5969, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5142, 0.4858], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5297, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.4805], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7415, 0.2585], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6627, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6656, 0.3344], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6953, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3373, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4932, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6880, 0.3120], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.6540, 0.3460], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6885, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.4863], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.4659], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3047, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6447, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7498, 0.2502], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6427, 0.3573], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5068, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6234, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4737, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3115, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6352, 0.3648], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3553, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4665, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.4766], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3766, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5233, 0.4767], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5185, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5335, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6478, 0.3522], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6238, 0.3762], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.4446], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5870, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4475, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5463, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3045, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4815, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4292, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4941, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4790, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4130, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2697, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5917, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3309, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4537, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5670, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6955, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3675, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7123, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5210, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7303, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4083, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.4776, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6691, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4233, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4330, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2here

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6325, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4659, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2877, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5670, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6085, 0.3915], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6330, 0.3670], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3120, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.4600], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2here

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6723, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4436, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.4378], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.4980], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5955, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7820, 0.2180], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4292, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5455, 0.4545], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6826, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6527, 0.3473], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4054, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6931, 0.3069], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4873, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.4533], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4299, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2here

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5224, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7516, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5767, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5351, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4436, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.4121], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4727, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.4263], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5855, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4330, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5891, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6880, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3277, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5746, 0.4254], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5641, 0.4359], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3531, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.4571], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3279, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4045, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3923, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3174, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5885, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6945, 0.3055], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3657, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5946, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7889, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5127, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4436, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.4698], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7603, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5701, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5559, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2484, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4746, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.4494], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4349, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4707, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.4659], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4980, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token shape: torch.Size([768])

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5414, 0.4586], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4097, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3099, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4971, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5273, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7162, 0.2838], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4145, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4639, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4109, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:1')here

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5370, 0.4630], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3854, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5550, 0.4450], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6872, 0.3128], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2457, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6469, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4688, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6721, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5156, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3084, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6077, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4115, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4144, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6343, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3756, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2111, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6610, 0.3390], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7547, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5000, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2451, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5623, 0.4377], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4917, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2397, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.3113, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4441, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5339, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5254, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5651, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5293, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5898, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.4698], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4737, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5020, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5643, 0.4357], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4446, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5903, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6901, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3337, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2383, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3469, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.4756], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3831, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.4883], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6573, 0.3427], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5361, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2383, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5195, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3531, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6146, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5746, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5122, 0.4878], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6011, 0.3989], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7543, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5312, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6505, 0.0000], device='cuda:1')[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5977, 0.4023], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2393, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7613, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6796, 0.3204], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6514, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4083, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6916, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6058, 0.3942], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5856, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2732, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6244, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6009, 0.3991], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2453, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3451, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7549, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2890, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5083, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3808, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6887, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2401, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.4446], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.4883], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5375, 0.4625], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5823, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5963, 0.4037], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4378, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4661, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4417, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.4121], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4941, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5224, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3863, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4102, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7299, 0.2701], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5263, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3564, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5545, 0.4455], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3086, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5988, 0.4012], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4397, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.5915, 0.4085], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6325, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6663, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6051, 0.3949], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7617, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6531, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3549, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] token_weights: torch.Size([2]) tensor([0.6397, 0.3603], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5875, 0.4125], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5993, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4426, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3558, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6169, 0.0000], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.2878, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5005, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5865, 0.4135], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4012, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7617, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6063, 0.3937], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6469, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5496, 0.4504], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4254, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5870, 0.4130], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6142, 0.3858], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3495, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2958, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7607, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6350, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2387, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2659, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7085, 0.2915], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5083, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5302, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3486, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3849, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5913, 0.4087], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6088, 0.3912], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5917, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5132, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6067, 0.3933], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4338, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5761, 0.4239], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4135, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.7666, 0.2334], device='cuda:0')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6199, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7268, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4417, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.5135, 0.4865], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5993, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6549, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4417, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6266, 0.3734], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6702, 0.3298], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7110, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4402, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6192, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5788, 0.4212], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')


[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.4951], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2386, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7599, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6146, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4177, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5622, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4854, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5583, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6215, 0.3785], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4436, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4776, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.4426, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6137, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3914, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6436, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4863, 0.0000], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6270, 0.3730], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4426, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here[DEBUG] token_weights: torch.Size([2]) tensor([0.6914, 0.0000], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4905, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4712, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6077, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5823, 0.4177], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5390, 0.4610], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3675, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3905, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5818, 0.4182], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6125, 0.3875], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6451, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4704, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4292, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4455, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5095, 0.4905], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6993, 0.0000], device='cuda:1')here

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4007, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7003, 0.2997], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6227, 0.3773], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6442, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6146, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6388, 0.3612], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3844, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7122, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6030, 0.3970], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5448, 0.4552], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5612, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.4571], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5063, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4995, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5089, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5775, 0.4225], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5988, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6174, 0.3826], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.4523], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5259, 0.4741], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.4620, 0.0000], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5960, 0.4040], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7042, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2923, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5492, 0.4508], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3920, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2465, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5200, 0.4800], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3183, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3650, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_weights: torch.Size([2]) tensor([0.4206, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7341, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4883, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4917, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4698, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4173, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6151, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6025, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5927, 0.4073], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6520, 0.3480], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6411, 0.3589], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5039, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4868, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.7249, 0.2751], device='cuda:1')

here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.4397], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2550, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5662, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2690, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5865, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3530, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3801, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6125, 0.3875], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5583, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3863, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4007, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4766, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5583, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7122, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5598, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5542, 0.4458], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5361, 0.4639], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7614, 0.0000], device='cuda:0')here

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2983, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3854, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7013, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4405, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5146, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6011, 0.3989], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5775, 0.4225], device='cuda:0')
here[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3882, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6893, 0.3107], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2447, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6018, 0.3982], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4865, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6086, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5995, 0.4005], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5137, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4371, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2here

[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5029, 0.4971], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4225, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5095, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6773, 0.3227], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5288, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4361, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5513, 0.4487], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4239, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5634, 0.4366], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6044, 0.3956], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2here

[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3923, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3416, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5689, 0.4311], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3024, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5424, 0.4576], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5059, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4436, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6095, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6225, 0.3775], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5296, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5545, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3975, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4244, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3007, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2498, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6007, 0.3993], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5554, 0.4446], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4383, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7198, 0.2802], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6610, 0.3390], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3854, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4029, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6156, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4385, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4388, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4206, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4937, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4475, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5588, 0.4412], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4591, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4911, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5068, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5259, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6732, 0.3268], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4610, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3433, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5380, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5449, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4951, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5865, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7077, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6080, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4441, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6388, 0.3612], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6105, 0.3895], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7535, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6817, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5116, 0.4884], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5107, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5794, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4824, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5117, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5813, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5477, 0.4523], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6151, 0.3849], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4494, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5533, 0.4467], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4571, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5827, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5078, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3975, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4010, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7272, 0.2728], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4252, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6721, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4961, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4834, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7450, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7110, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7310, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6073, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6470, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 0 of 2

here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6562, 0.3438], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5037, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5215, 0.4785], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6049, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6137, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2509, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5234, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5927, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2878, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.2502, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6088, 0.3912], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5593, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2505, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7017, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5042, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2987, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2440, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5595, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6118, 0.3882], device='cuda:1')[DEBUG] token shape: torch.Size([768])

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5380, 0.4620], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4513, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5453, 0.4547], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')[DEBUG] iterate over top k experts. at expert: 1 of 2

here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4600, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6118, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7553, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4576, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5135, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2494, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5629, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6169, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5775, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4206, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.8056, 0.1944], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4717, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5639, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5879, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5761, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2378, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6584, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7126, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6320, 0.3680], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3868, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6976, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2528, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4941, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.1694, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5574, 0.4426], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5946, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6072, 0.3928], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6137, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6025, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6615, 0.3385], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5997, 0.4003], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2444, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5756, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3339, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7502, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.1663, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5617, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5663, 0.4337], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5971, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2961, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5615, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3702, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5794, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3528, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5525, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6197, 0.3803], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5409, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3942, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4932, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3789, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4741, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7210, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5390, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5905, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5063, 0.4937], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5393, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6567, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5715, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6309, 0.3691], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5777, 0.4223], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4551, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6063, 0.3937], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4135, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3247, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])here

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5088, 0.4912], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2602, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5322, 0.4678], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2602, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5988, 0.4012], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4902, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')[DEBUG] token_weights: torch.Size([2]) tensor([0.5383, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7080, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5559, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4571, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5341, 0.4659], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2898, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5118, 0.4882], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2576, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.4581], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3504, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5506, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4693, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5458, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2587, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4893, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5448, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5176, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7027, 0.2973], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5583, 0.4417], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5870, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4187, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4078, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6179, 0.3821], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3036, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4922, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6316, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5160, 0.4840], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5390, 0.4610], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5413, 0.4587], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6032, 0.3968], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5990, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5748, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4450, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3279, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6637, 0.3363], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5166, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5224, 0.4776], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.2890, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6047, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3927, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6053, 0.3947], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.4963, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3630, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5244, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3741, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3951, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5679, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7491, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.3320, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4073, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7498, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6188, 0.3812], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4407, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5419, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.7495, 0.0000], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5387, 0.0000], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5564, 0.4436], device='cuda:0')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.6402, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4958, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6197, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7560, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5049, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5487, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4634, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5400, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4111, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4912, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.4183, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5424, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6765, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.7506, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.5993, 0.4007], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
here
[DEBUG] token_weights: torch.Size([2]) tensor([0.6420, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.3831, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.2502, 0.0000], device='cuda:1')
here
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_weights: torch.Size([2]) tensor([0.5794, 0.0000], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_weights: torch.Size([2]) tensor([0.5746, 0.0000], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5283, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4450, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4121, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.5898, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.6719, 0.3281], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3069, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] iterate over top k experts. at expert: 1 of 2

here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.7622, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4756, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')


[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2874, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4649, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6132, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7472, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3947, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.8306, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2505, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here[DEBUG] iterate over top k experts. at expert: 1 of 2

[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4054, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.3271, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3863, 0.0000], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2576, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5708, 0.4292], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4844, 0.0000], device='cuda:1')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7556, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.3847, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6661, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4504, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.8337, 0.0000], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4158, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5429, 0.4571], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4235, 0.0000], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5603, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7039, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6298, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.2528, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6472, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7372, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6058, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5970, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7322, 0.2678], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3529, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6211, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.3970, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.2790, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5826, 0.4174], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6206, 0.3794], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5966, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4095, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4937, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4607, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here[DEBUG] iterate over top k experts. at expert: 0 of 2

here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.7086, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6169, 0.3831], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
here
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5732, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.4285, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.6753, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.4805, 0.0000], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7398, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token_expert_ids torch.Size([2]) tensor([0, 1], device='cuda:1')
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5811, 0.4189], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_weights: torch.Size([2]) tensor([0.7398, 0.0000], device='cuda:0')
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')

here
[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([1, 0], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.6077, 0.3923], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5737, 0.4263], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:1')

[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([True, True], device='cuda:0')

[DEBUG] iterate over top k experts. at expert: 0 of 2
[DEBUG] iterate over top k experts. at expert: 0 of 2
here
here
[DEBUG] iterate over top k experts. at expert: 1 of 2
[DEBUG] iterate over top k experts. at expert: 1 of 2
here
here
[DEBUG] token shape: torch.Size([768])
[DEBUG] token shape: torch.Size([768])
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 1, -1], device='cuda:1')
[DEBUG] token_expert_ids torch.Size([2]) tensor([ 0, -1], device='cuda:0')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5718, 0.0000], device='cuda:1')
[DEBUG] token_weights: torch.Size([2]) tensor([0.5098, 0.0000], device='cuda:0')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:1')
[DEBUG] token_expert_id_mask: torch.Size([2])
tensor([ True, False], device='cuda:0')
