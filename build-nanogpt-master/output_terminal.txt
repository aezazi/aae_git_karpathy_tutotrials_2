Running in distributed environment. Initializing FSDP

Running in distributed environment. Initializing FSDP


GPTConfig instantiated with block size: 1024, vocab size: 50304, n_layer: 12, n_head: 12, n_embd: 768

GPTConfig instantiated with block size: 1024, vocab size: 50304, n_layer: 12, n_head: 12, n_embd: 768

FSDP initialized on device: cuda:0, rank: 0, local rank: 0, world size: 2


FSDP initialized on device: cuda:1, rank: 1, local rank: 1, world size: 2

Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1
Rank 1: Managing experts 2 to 3
Rank 0: Managing experts 0 to 1

Total parameters: 237,092,400


Total parameters: 237,092,400


Optimizer initialized on GPU rank 1, device cuda:1

Optimizer initialized on GPU rank 0, device cuda:0

effective batch size desired: 524288

Scheduler initialized on GPU rank 1, of 2
accumulation steps desired: 16


Scheduler initialized on GPU rank 0, of 2

[DEBUG] Rank 1  started training step: 0
[DEBUG] Rank 0  started training step: 0
[DEBUG] Rank 1: Getting gate assignments...
[DEBUG] shape of data to each gpu: [(16384, 768), (16384, 768)]
[DEBUG] Rank 0: Getting gate assignments...
[DEBUG] Rank 1: Gate assignments complete, top_k_ids shape: torch.Size([16384, 2])
[DEBUG] Rank 0: Gate assignments complete, top_k_ids shape: torch.Size([16384, 2])
[DEBUG] Rank 1: Getting expert assignments...
[DEBUG] Rank 0: Getting expert assignments...
[DEBUG] Rank 0: Sending 14539 tokens to GPU 0
[DEBUG] Rank 0: Sending 12612 tokens to GPU 1
[DEBUG] Rank 0: Starting token communication...
----------------------------------------------------------------------
[DEBUG] Rank 0 entered _communicate_tokens
[DEBUG] Rank 0 shape token_expert_local_id_assignments_padded : torch.Size([14539, 2])
[DEBUG] Rank 0 token_weights_padded: torch.Size([14539, 2])
[DEBUG] Rank 0 shape token_expert_local_id_assignments_padded : torch.Size([12612, 2])
[DEBUG] Rank 0 token_weights_padded: torch.Size([12612, 2])
[DEBUG] Rank 0 send counts after looping gpus: = [14539, 12612], sum = 27151, tensor_rows = 12612
[DEBUG] Rank 1: Sending 14727 tokens to GPU 0
[DEBUG] Rank 1: Sending 12586 tokens to GPU 1
[DEBUG] Rank 1: Starting token communication...
[DEBUG] Rank 0 input_split_sizes_tensor: tensor([14539, 12612], device='cuda:0', dtype=torch.int32)
----------------------------------------------------------------------
[DEBUG] Rank 0 initiating dist.all_to_all_single(recv_counts, send_counts)
[DEBUG] Rank 1 entered _communicate_tokens
[DEBUG] Rank 1 shape token_expert_local_id_assignments_padded : torch.Size([14727, 2])
[DEBUG] Rank 1 token_weights_padded: torch.Size([14727, 2])
[DEBUG] Rank 1 shape token_expert_local_id_assignments_padded : torch.Size([12586, 2])
[DEBUG] Rank 1 token_weights_padded: torch.Size([12586, 2])
[DEBUG] Rank 1 send counts after looping gpus: = [14727, 12586], sum = 27313, tensor_rows = 12586
[DEBUG] Rank 1 input_split_sizes_tensor: tensor([14727, 12586], device='cuda:1', dtype=torch.int32)
[DEBUG] Rank 1 initiating dist.all_to_all_single(recv_counts, send_counts)
[DEBUG] Rank 0 recv_counts: [14539, 14727]
[DEBUG] Rank 1 recv_counts: [12612, 12586]
[DEBUG] Rank 0 N_recv: 29266
[DEBUG] Rank 1 N_recv: 25198

[DEBUG]  all-to-all completed


[DEBUG]  all-to-all completed

[DEBUG] recv_tokens shape: torch.Size([25198, 768]) sample:
tensor([[-0.6603,  1.4664, -2.0283,  ..., -2.5188, -1.5531,  1.1216],
        [ 0.7716,  3.0206, -0.6433,  ..., -1.1497, -1.7753,  0.5258],
        [ 0.7732,  1.7949,  0.3880,  ..., -0.1529, -2.6636,  0.0137],
        ...,
        [-0.6697,  1.7638, -0.8852,  ..., -0.8460, -3.0561, -0.7363],
        [-0.8981,  0.9513,  0.1860,  ..., -0.9275, -1.2755, -1.2504],
        [-1.8675,  0.8933,  0.9755,  ..., -1.5717, -0.3146, -0.7213]],
       device='cuda:1')

[DEBUG] recv_tokens shape: torch.Size([29266, 768]) sample:
tensor([[-0.6603,  1.4664, -2.0283,  ..., -2.5188, -1.5531,  1.1216],
        [-0.0206,  1.0530, -0.0684,  ..., -0.6291, -3.5399,  0.2567],
        [-0.1193,  2.5328,  0.1750,  ...,  0.1167, -2.9627, -0.9365],
        ...,
        [-2.7438, -0.4154, -0.6484,  ..., -1.7603, -0.5287, -0.9050],
        [-1.2202,  0.4806, -1.1232,  ..., -1.7225,  0.0444, -0.3257],
        [-1.8926,  1.9401, -1.3023,  ..., -0.6211, -0.8981,  1.0728]],
       device='cuda:0')

[DEBUG] Rank 1: Token communication complete, received 25198 tokens
[DEBUG] Rank 0: Token communication complete, received 29266 tokens

[DEBUG] recv_tokens: tensor([[-0.6603,  1.4664, -2.0283,  1.0832,  1.4664, -0.3959, -0.0663],
        [ 0.7716,  3.0206, -0.6433,  1.2234,  1.7298,  1.5908, -0.9859],
        [ 0.7732,  1.7949,  0.3880,  2.4834,  0.7568,  0.6284, -0.6529],
        [-0.0206,  1.0530, -0.0684,  2.0670,  2.2221,  0.4416, -1.5834],
        [-0.8333,  1.4109,  1.3974,  2.0434,  0.4654, -0.1839,  0.0676],
        [-0.1193,  2.5328,  0.1750,  0.7508,  0.5540,  0.3991,  0.1403],
        [-0.7236,  1.0258,  0.3279,  2.1820,  0.2081,  1.3377, -0.5297],
        [-0.6697,  1.7638, -0.8852,  0.7606,  1.3092, -1.5984, -0.6736],
        [-0.8981,  0.9513,  0.1860,  0.4250,  1.7104,  0.2132, -1.5943],
        [-1.8675,  0.8933,  0.9755,  1.6657, -0.3290, -1.0952, -0.1841]],
       device='cuda:1')
----------------------------------------------------------------------
[DEBUG] Rank 1 entered _process_local_experts

[DEBUG] recv_tokens: tensor([[-0.6603,  1.4664, -2.0283,  1.0832,  1.4664, -0.3959, -0.0663],
        [-0.0206,  1.0530, -0.0684,  2.0670,  2.2221,  0.4416, -1.5834],
        [-0.1193,  2.5328,  0.1750,  0.7508,  0.5540,  0.3991,  0.1403],
        [-0.6697,  1.7638, -0.8852,  0.7606,  1.3092, -1.5984, -0.6736],
        [-0.8981,  0.9513,  0.1860,  0.4250,  1.7104,  0.2132, -1.5943],
        [-1.8675,  0.8933,  0.9755,  1.6657, -0.3290, -1.0952, -0.1841],
        [-0.0215, -0.1290, -1.4955,  1.3034, -1.1533, -0.5260, -0.2869],
        [-2.7438, -0.4154, -0.6484,  1.5068,  0.3479, -1.0761, -0.4026],
        [-1.2202,  0.4806, -1.1232, -0.9073,  1.2913, -1.5198, -0.0812],
        [-1.8926,  1.9401, -1.3023, -0.1579,  1.6223, -0.5984, -0.3849]],
       device='cuda:0')
[DEBUG] Rank 1: Processing 25198 tokens through local experts
----------------------------------------------------------------------
[DEBUG] Rank 1: Input shapes - tokens: torch.Size([25198, 768]), expert_ids: torch.Size([25198, 2]), weights: torch.Size([25198, 2])
[DEBUG] Rank 0 entered _process_local_experts
[DEBUG] Rank 1: Starting token-by-token processing...
[DEBUG] Rank 0: Processing 29266 tokens through local experts
[DEBUG] Rank 1: Processing token 0/25198
[DEBUG] Rank 0: Input shapes - tokens: torch.Size([29266, 768]), expert_ids: torch.Size([29266, 2]), weights: torch.Size([29266, 2])
[DEBUG] token_weights: torch.Size([2]) tensor([0.5346, 0.0000], device='cuda:1')
[DEBUG] Rank 0: Starting token-by-token processing...
[DEBUG] Rank 0: Processing token 0/29266
[DEBUG] token_weights: torch.Size([2]) tensor([0.4654, 0.0000], device='cuda:0')
[DEBUG] Rank 1: Processing token 5000/25198
[DEBUG] token_weights: torch.Size([2]) tensor([0.3956, 0.0000], device='cuda:1')
[DEBUG] Rank 0: Processing token 5000/29266
[DEBUG] token_weights: torch.Size([2]) tensor([0.5467, 0.0000], device='cuda:0')
[DEBUG] Rank 1: Processing token 10000/25198
[DEBUG] token_weights: torch.Size([2]) tensor([0.2191, 0.0000], device='cuda:1')
[DEBUG] Rank 0: Processing token 10000/29266
[DEBUG] token_weights: torch.Size([2]) tensor([0.4620, 0.0000], device='cuda:0')
[DEBUG] Rank 1: Processing token 15000/25198
[DEBUG] token_weights: torch.Size([2]) tensor([0.2914, 0.0000], device='cuda:1')
[DEBUG] Rank 0: Processing token 15000/29266
[DEBUG] token_weights: torch.Size([2]) tensor([0.7172, 0.2828], device='cuda:0')
[DEBUG] Rank 1: Processing token 20000/25198
[DEBUG] token_weights: torch.Size([2]) tensor([0.2418, 0.0000], device='cuda:1')
[DEBUG] Rank 0: Processing token 20000/29266
[DEBUG] token_weights: torch.Size([2]) tensor([0.5472, 0.0000], device='cuda:0')
[DEBUG] Rank 1: Processing token 25000/25198
[DEBUG] token_weights: torch.Size([2]) tensor([0.4542, 0.0000], device='cuda:1')
[DEBUG] Rank 0: Processing token 25000/29266
[DEBUG] token_weights: torch.Size([2]) tensor([0.6723, 0.3277], device='cuda:0')
[DEBUG] Rank 1: tokens_to_send_back_to_this_gpu_rank shape: torch.Size([14727, 768]) from gpu_rank: 0  token_positions shape: torch.Size([14727])
[DEBUG] Rank 1: tokens_to_send_back_to_this_gpu_rank shape: torch.Size([10471, 768]) from gpu_rank: 1  token_positions shape: torch.Size([12586])
[DEBUG] Rank 0: tokens_to_send_back_to_this_gpu_rank shape: torch.Size([14539, 768]) from gpu_rank: 0  token_positions shape: torch.Size([14539])
[DEBUG] Rank 0: tokens_to_send_back_to_this_gpu_rank shape: torch.Size([12612, 768]) from gpu_rank: 1  token_positions shape: torch.Size([12612])
